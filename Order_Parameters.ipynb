{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prerequisite packages\n",
    "# the missing packages can be installed using the command \n",
    "#pip install <package name>\n",
    "#or\n",
    "#pip3 install <package name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymatgen import Lattice, Structure, Molecule\n",
    "from pymatgen.analysis import structure_analyzer, local_env\n",
    "from pymatgen.analysis.chemenv.coordination_environments import voronoi\n",
    "import os\n",
    "import sys\n",
    "import ase.io\n",
    "import pymatgen.io.ase\n",
    "import math\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example configuration to get the order parameters\n",
    "# the desired configuration can be uncommented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = 'SiGe_Si_substrate'\n",
    "\n",
    "#configuration = 'SiGe_Ge_substrate'\n",
    "\n",
    "#configuration = 'SiGe_random'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the order parameters\n",
    "#This may take some time. For multyprocessor machines increase the number of processors for the calculation\n",
    "\n",
    "#Example:    N_processors = 10\n",
    "\n",
    "\n",
    "N_processors = 11\n",
    "\n",
    "\n",
    "#Set the number of output decimals for the calculated features\n",
    "\n",
    "n_decimals = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the lattice constants of bulk system for the reference to be used for the global features\n",
    "# This are for the bulk Silicon:\n",
    "# bulk_a=5.475\n",
    "# bulk_b=5.475\n",
    "# bulk_c=5.475\n",
    "\n",
    "bulk_a=5.475\n",
    "bulk_b=5.475\n",
    "bulk_c=5.475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original unit cell has been increased by 4 times.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>1_order_a</th>\n",
       "      <th>1_order_b</th>\n",
       "      <th>1_order_c</th>\n",
       "      <th>2_order_a</th>\n",
       "      <th>2_order_b</th>\n",
       "      <th>2_order_c</th>\n",
       "      <th>3_order_a</th>\n",
       "      <th>3_order_b</th>\n",
       "      <th>3_order_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ge</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ge</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ge</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ge</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ge</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  1_order_a  1_order_b  1_order_c  2_order_a  2_order_b  2_order_c  \\\n",
       "13     Si      0.568      0.568      0.505      0.503      0.503      0.460   \n",
       "5      Si      0.568      0.568      0.505      0.503      0.503      0.460   \n",
       "3      Si      0.957      0.957      0.910      0.680      0.680      0.555   \n",
       "6      Si      0.957      0.957      0.910      0.680      0.680      0.555   \n",
       "0      Si      0.568      0.568      0.505      0.503      0.503      0.460   \n",
       "2      Ge      0.553      0.553      0.495      0.479      0.479      0.469   \n",
       "1      Ge      0.553      0.553      0.495      0.479      0.479      0.469   \n",
       "4      Ge      0.977      0.977      0.951      0.729      0.729      0.596   \n",
       "8      Ge      0.977      0.977      0.951      0.729      0.729      0.596   \n",
       "12     Ge      0.553      0.553      0.495      0.479      0.479      0.469   \n",
       "\n",
       "    3_order_a  3_order_b  3_order_c  \n",
       "13      0.384      0.384      0.297  \n",
       "5       0.384      0.384      0.297  \n",
       "3       0.462      0.462      0.350  \n",
       "6       0.462      0.462      0.350  \n",
       "0       0.384      0.384      0.297  \n",
       "2       0.383      0.383      0.310  \n",
       "1       0.383      0.383      0.310  \n",
       "4       0.503      0.503      0.368  \n",
       "8       0.503      0.503      0.368  \n",
       "12      0.383      0.383      0.310  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Load the configuration\n",
    "\n",
    "structure = pymatgen.Structure.from_file(configuration+'/CONTCAR')\n",
    "structure_save=structure.copy()\n",
    "# Make a supercell to distinguish the atoms from its replicated counterparts (needed only for the small unit cells)\n",
    "\n",
    "##\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "# Check if a larger supercell is needed for the order parameters calculation\n",
    "\n",
    "def checkIfDuplicates(listOfElems):\n",
    "    ''' Check if given list contains any duplicates '''\n",
    "    if len(listOfElems) == len(set(listOfElems)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "sizestructure=len(structure.atomic_numbers)\n",
    "\n",
    "M=np.array([1,1,1])\n",
    "result=True\n",
    "for w in range(sizestructure):\n",
    "            while result:\n",
    "                cell_dict=local_env.VoronoiNN().get_nn_info(structure,w)\n",
    "                neighbors=[cell_dict[v]['site_index'] for v in range(len(cell_dict))]\n",
    "                result=checkIfDuplicates(neighbors)\n",
    "                if result:\n",
    "                        zer=[0,0,0]\n",
    "                        zer[list(structure.lattice.abc).index(min(list(structure.lattice.abc)))]=1\n",
    "                        M+=np.array(zer)\n",
    "                        structure.make_supercell(M)\n",
    "                        cell_dict=local_env.VoronoiNN().get_nn_info(structure,w)\n",
    "                        neighbors=[cell_dict[v]['site_index'] for v in range(len(cell_dict))]\n",
    "                        result=checkIfDuplicates(neighbors)\n",
    "##\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                \n",
    "structure_save.make_supercell(M)\n",
    "structure = structure_save\n",
    "scale=np.product(M)\n",
    "\n",
    "print(\"The original unit cell has been increased by \" + str(scale) +\" times.\")\n",
    "\n",
    "lat_a=structure.lattice.a\n",
    "lat_b=structure.lattice.b\n",
    "lat_c=structure.lattice.c\n",
    "lat_a=lat_a/np.round(lat_a/bulk_a,decimals=0)\n",
    "lat_b=lat_b/np.round(lat_b/bulk_b,decimals=0)\n",
    "lat_c=lat_c/np.round(lat_c/bulk_c,decimals=0)\n",
    "\n",
    "sizestructure=len(structure.atomic_numbers)\n",
    "\n",
    "\n",
    "face_areas_r=[]\n",
    "neighbors=[]\n",
    "element_nn_list=[]\n",
    "face_area_dist=[]\n",
    "neighbors_xyz=[]\n",
    "volumes_r=[]\n",
    "\n",
    "df_all=pd.DataFrame()\n",
    "df_all_atom=pd.DataFrame()\n",
    "\n",
    "nn1_old=[]\n",
    "nn2_old=[]\n",
    "nn3_old=[]\n",
    "\n",
    "\n",
    "def calculate_local_properties(dictionary, neighbors, core_atom, face_areas_r):\n",
    "    dict_core=[dictionary[x] for x in core_atom['symbol']]\n",
    "    dict_tot=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(dict_core)):\n",
    "\n",
    "        element_list_neigh=neighbors['element_nn_list'] #[i]\n",
    "\n",
    "        areas=face_areas_r #['face_areas_r'] #[i]\n",
    "\n",
    "    \n",
    "        values_n=np.array([dictionary[x] for x in element_list_neigh])\n",
    "\n",
    "        dict_tot.append(np.sum(areas*np.abs(values_n-dict_core[i]))/np.sum(areas))\n",
    "\n",
    "    features=[np.max(dict_tot), np.min(dict_tot), np.mean(dict_tot), np.sum(np.abs(dict_tot-np.mean(dict_tot)))/len(dict_tot),dict_tot]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_ionic_character(dictionary, neighbors, core_atom, face_areas_r):\n",
    "    \n",
    "    dict_core=[dictionary[x] for x in core_atom['symbol']]\n",
    "    dict_tot=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(dict_core)):\n",
    "\n",
    "        element_list_neigh=neighbors['element_nn_list']\n",
    "        areas=face_areas_r #['face_areas_r']\n",
    "\n",
    "    \n",
    "        values_n=np.array([dictionary[x] for x in element_list_neigh])\n",
    "\n",
    "        dict_tot.append(np.sum(areas*np.abs(1-np.exp(-0.25*np.power((values_n-dict_core[i]), 2))))/np.sum(areas))\n",
    "\n",
    "    features=[np.max(dict_tot), np.min(dict_tot), np.mean(dict_tot), np.sum(np.abs(dict_tot-np.mean(dict_tot)))/len(dict_tot),dict_tot]\n",
    "\n",
    "    return features\n",
    "           \n",
    "            \n",
    "def get_atomic_env(w):\n",
    "            global df_all\n",
    "            global df_all_atom     \n",
    "            df=pd.DataFrame()\n",
    "            df_atom=pd.DataFrame()\n",
    "            cell_dict=local_env.VoronoiNN().get_nn_info(structure,w)\n",
    "            df['index']=[w]*len(cell_dict)\n",
    "            df['symbol']=[str(structure._sites[w]).split()[-1]]*len(cell_dict)\n",
    "            df['neighbors']=([cell_dict[v]['site_index'] for v in range(len(cell_dict))])\n",
    "            df['element_nn_list']=([cell_dict[v]['site'].species_string for v in range(len(cell_dict))])\n",
    "            df['volumes_r']=([cell_dict[v]['poly_info']['volume'] for v in range(len(cell_dict))])\n",
    "            df['face_areas_r']=([cell_dict[v]['poly_info']['area'] for v in range(len(cell_dict))])   \n",
    "            df['face_area_dist']=([cell_dict[v]['poly_info']['face_dist']*2 for v in range(len(cell_dict))])\n",
    "            df['x']=[structure.cart_coords[w][0]]*len(cell_dict)\n",
    "            df['y']=[structure.cart_coords[w][1]]*len(cell_dict)\n",
    "            df['z']=[structure.cart_coords[w][2]]*len(cell_dict)\n",
    "            df['neighbors_x']=([cell_dict[v]['site'].coords[0] for v in range(len(cell_dict))])\n",
    "            df['neighbors_y']=([cell_dict[v]['site'].coords[1] for v in range(len(cell_dict))])\n",
    "            df['neighbors_z']=([cell_dict[v]['site'].coords[2] for v in range(len(cell_dict))])\n",
    "            df['dist_x']=abs(df['x']-df['neighbors_x'])\n",
    "            df['dist_y']=abs(df['y']-df['neighbors_y'])\n",
    "            df['dist_z']=abs(df['z']-df['neighbors_z'])\n",
    "            df['sinphi2']=df['dist_y']**2/(df['dist_x']**2+df['dist_y']**2+1E-99)\n",
    "            df['cosphi2']=df['dist_x']**2/(df['dist_x']**2+df['dist_y']**2+1E-99)\n",
    "            df['sintheta2']=(df['dist_x']**2+df['dist_y']**2)/(df['dist_x']**2+df['dist_y']**2+df['dist_z']**2+1E-99)\n",
    "            df['costheta2']=df['dist_z']**2/(df['dist_x']**2+df['dist_y']**2+df['dist_z']**2+1E-99)\n",
    "            df['face_areas_r_a']=df['face_areas_r']*df['cosphi2']*df['sintheta2']\n",
    "            df['face_areas_r_b']=df['face_areas_r']*df['sinphi2']*df['sintheta2']\n",
    "            df['face_areas_r_c']=df['face_areas_r']*df['costheta2']\n",
    "            df_atom['index']=[w]\n",
    "            df_atom['symbol']=[str(structure._sites[w]).split()[-1]]\n",
    "            df_atom['maximum_packing_efficiency']=np.round((4/3*np.pi*(df['face_area_dist'].min()/2)**3)/(df['volumes_r'].sum()),decimals=n_decimals)\n",
    "\n",
    "            df_atom['bond_length']=np.round(np.dot(df['face_area_dist'],np.transpose(df['face_areas_r']))/df['face_areas_r'].sum(),decimals=n_decimals)\n",
    "            df_atom['bond_length_a']=np.round(np.dot(df['face_area_dist'],np.transpose(df['face_areas_r_a']))/df['face_areas_r_a'].sum(),decimals=n_decimals)\n",
    "            df_atom['bond_length_b']=np.round(np.dot(df['face_area_dist'],np.transpose(df['face_areas_r_b']))/df['face_areas_r_b'].sum(),decimals=n_decimals)\n",
    "            df_atom['bond_length_c']=np.round(np.dot(df['face_area_dist'],np.transpose(df['face_areas_r_c']))/df['face_areas_r_c'].sum(),decimals=n_decimals)\n",
    "            \n",
    "            df_atom['var_bond_length']=np.round(np.dot((df['face_area_dist']-df_atom['bond_length'].values)**2, np.transpose(df['face_areas_r']))/(df['face_areas_r'].sum()),decimals=n_decimals)\n",
    "            df_atom['var_bond_length_a']=np.round(np.dot((df['face_area_dist']-df_atom['bond_length_a'].values)**2, np.transpose(df['face_areas_r_a']))/(df['face_areas_r_a'].sum()),decimals=n_decimals)\n",
    "            df_atom['var_bond_length_b']=np.round(np.dot((df['face_area_dist']-df_atom['bond_length_b'].values)**2, np.transpose(df['face_areas_r_b']))/(df['face_areas_r_b'].sum()),decimals=n_decimals)\n",
    "            df_atom['var_bond_length_c']=np.round(np.dot((df['face_area_dist']-df_atom['bond_length_c'].values)**2, np.transpose(df['face_areas_r_c']))/(df['face_areas_r_c'].sum()),decimals=n_decimals)\n",
    "\n",
    "            df_atom['min_cell_volume']=np.round(df['volumes_r'].min(),decimals=n_decimals)\n",
    "            df_atom['max_cell_volume']=np.round(df['volumes_r'].max(),decimals=n_decimals)\n",
    "            df_atom['mean_cell_volume']=np.round(df['volumes_r'].mean(),decimals=n_decimals)\n",
    "            df_atom['var_cell_volume']=np.round(df['volumes_r'].var(),decimals=n_decimals)\n",
    "            df_atom['tot_cell_volume']=np.round(df['volumes_r'].sum(),decimals=n_decimals)\n",
    "\n",
    "            df_atom['mean_face_area']=np.round(df['face_areas_r'].mean() ,decimals=n_decimals)\n",
    "            df_atom['max_face_area']=np.round(df['face_areas_r'].max(),decimals=n_decimals)\n",
    "            df_atom['min_face_area']=np.round(df['face_areas_r'].min(),decimals=n_decimals)\n",
    "            df_atom['var_face_area']=np.round(df['face_areas_r'].var(),decimals=n_decimals)\n",
    "            df_atom['tot_face_area']=np.round(df['face_areas_r'].sum(),decimals=n_decimals)\n",
    "            df_atom['mean_face_area_a']=np.round(df['face_areas_r_a'].mean() ,decimals=n_decimals)\n",
    "            df_atom['max_face_area_a']=np.round(df['face_areas_r_a'].max(),decimals=n_decimals)\n",
    "            df_atom['min_face_area_a']=np.round(df['face_areas_r_a'].min(),decimals=n_decimals)\n",
    "            df_atom['var_face_area_a']=np.round(df['face_areas_r_a'].var(),decimals=n_decimals)\n",
    "            df_atom['tot_face_area_a']=np.round(df['face_areas_r_a'].sum(),decimals=n_decimals)\n",
    "            df_atom['mean_face_area_b']=np.round(df['face_areas_r_b'].mean() ,decimals=n_decimals)\n",
    "            df_atom['max_face_area_b']=np.round(df['face_areas_r_b'].max(),decimals=n_decimals)\n",
    "            df_atom['min_face_area_b']=np.round(df['face_areas_r_b'].min(),decimals=n_decimals)\n",
    "            df_atom['var_face_area_b']=np.round(df['face_areas_r_b'].var(),decimals=n_decimals)\n",
    "            df_atom['tot_face_area_b']=np.round(df['face_areas_r_b'].sum(),decimals=n_decimals)\n",
    "            df_atom['mean_face_area_c']=np.round(df['face_areas_r_c'].mean() ,decimals=n_decimals)\n",
    "            df_atom['max_face_area_c']=np.round(df['face_areas_r_c'].max(),decimals=n_decimals)\n",
    "            df_atom['min_face_area_c']=np.round(df['face_areas_r_c'].min(),decimals=n_decimals)\n",
    "            df_atom['var_face_area_c']=np.round(df['face_areas_r_c'].var(),decimals=n_decimals)\n",
    "            df_atom['tot_face_area_c']=np.round(df['face_areas_r_c'].sum(),decimals=n_decimals)\n",
    "            df_atom['coordination']=np.round((df['face_areas_r'].sum())**2/((df['face_areas_r']**2).sum()),decimals=n_decimals)\n",
    "            df_atom['coordination_a']=np.round((df['face_areas_r_a'].sum())**2/((df['face_areas_r_a']**2).sum()),decimals=n_decimals)\n",
    "            df_atom['coordination_b']=np.round((df['face_areas_r_b'].sum())**2/((df['face_areas_r_b']**2).sum()),decimals=n_decimals)\n",
    "            df_atom['coordination_c']=np.round((df['face_areas_r_c'].sum())**2/((df['face_areas_r_c']**2).sum()),decimals=n_decimals)\n",
    "            electronegativities={\"name\":'electronegativities',\"Al\":1.61, \"In\":1.78, \"Ga\": 1.81, \"O\":3.44, \"Si\" : 1.90, \"Ge\" : 2.01}\n",
    "            local_properties=[electronegativities]\n",
    "            for dictionary in local_properties:\n",
    "                property_name='electronegativities' #[ k for k,v in locals().items() if v is dictionary][1]    \n",
    "                features=calculate_local_properties(dictionary, df[['index','element_nn_list']], df_atom[['index','symbol']], df['face_areas_r'])\n",
    "                df_atom[property_name]=np.round(features[4],decimals=n_decimals)\n",
    "            features=calculate_ionic_character(electronegativities, df[['index','element_nn_list']],  df_atom[['index','symbol']], df['face_areas_r'])\n",
    "            df_atom['ionic_character']=np.round(features[4],decimals=n_decimals)\n",
    "            for dictionary in local_properties:\n",
    "                property_name='electronegativities_a' #[ k for k,v in locals().items() if v is dictionary][1]    \n",
    "                features=calculate_local_properties(dictionary, df[['index','element_nn_list']], df_atom[['index','symbol']], df['face_areas_r_a'])\n",
    "                df_atom[property_name]=np.round(features[4],decimals=n_decimals)\n",
    "            features=calculate_ionic_character(electronegativities, df[['index','element_nn_list']],  df_atom[['index','symbol']], df['face_areas_r_a'])\n",
    "            df_atom['ionic_character_a']=np.round(features[4],decimals=n_decimals)\n",
    "            for dictionary in local_properties:\n",
    "                property_name='electronegativities_b' #[ k for k,v in locals().items() if v is dictionary][1]    \n",
    "                features=calculate_local_properties(dictionary, df[['index','element_nn_list']], df_atom[['index','symbol']], df['face_areas_r_b'])\n",
    "                df_atom[property_name]=np.round(features[4],decimals=n_decimals)\n",
    "            features=calculate_ionic_character(electronegativities, df[['index','element_nn_list']],  df_atom[['index','symbol']], df['face_areas_r_b'])\n",
    "            df_atom['ionic_character_b']=np.round(features[4],decimals=n_decimals)\n",
    "            for dictionary in local_properties:\n",
    "                property_name='electronegativities_c' #[ k for k,v in locals().items() if v is dictionary][1]    \n",
    "                features=calculate_local_properties(dictionary, df[['index','element_nn_list']], df_atom[['index','symbol']], df['face_areas_r_c'])\n",
    "                df_atom[property_name]=np.round(features[4],decimals=n_decimals)\n",
    "            features=calculate_ionic_character(electronegativities, df[['index','element_nn_list']],  df_atom[['index','symbol']], df['face_areas_r_c'])\n",
    "            df_atom['ionic_character_c']=np.round(features[4],decimals=n_decimals)            \n",
    "            df_atom['lat_a']=[lat_a] #*(sizestructure)\n",
    "            df_atom['lat_b']=[lat_b] #*(sizestructure)\n",
    "            df_atom['lat_c']=[lat_c] #*(sizestructure)\n",
    "            df_atom['x']=df['x'].mean()\n",
    "            df_atom['y']=df['y'].mean()\n",
    "            df_atom['z']=df['z'].mean()\n",
    "            df_all=pd.concat([df_all,df])\n",
    "            df_all_atom=pd.concat([df_all_atom,df_atom])\n",
    "            return df_all, df_all_atom\n",
    "\n",
    "\n",
    "indices = np.arange(0,sizestructure,scale)\n",
    "\n",
    "\n",
    "def slice_iterable(iterable, chunk):\n",
    "    \"\"\"\n",
    "    Slices an iterable into chunks of size n\n",
    "    :param chunk: the number of items per slice\n",
    "    :type chunk: int\n",
    "    :type iterable: collections.Iterable\n",
    "    :rtype: collections.Generator\n",
    "    \"\"\"\n",
    "    _it = iter(iterable)\n",
    "    return itertools.takewhile(\n",
    "        bool, (tuple(itertools.islice(_it, chunk)) for _ in itertools.count(0))\n",
    "    )\n",
    "\n",
    "\n",
    "list_of_dict = [dict.fromkeys(indices) for _ in range(12)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for dictionary in list_of_dict:\n",
    "    for n in indices:\n",
    "        dictionary[n]=[]\n",
    "def worker(enumerated_comps):\n",
    "    global df_all\n",
    "    global df_all_atom\n",
    "\n",
    "    for ind, i in enumerated_comps:\n",
    "            try:\n",
    "                if len(df_all[df_all['index']==i])==0:\n",
    "                    df_all, df_all_atom=get_atomic_env(i)\n",
    "            except:\n",
    "                df_all, df_all_atom=get_atomic_env(i)\n",
    "            \n",
    "\n",
    "            element_0=df_all[(df_all['index']==i)]['symbol'].drop_duplicates().values\n",
    "            \n",
    "            w_tot_1=[]\n",
    "            w_tot_2=[]\n",
    "            w_tot_3=[]            \n",
    "            w_tot_1_a=[]\n",
    "            w_tot_2_a=[]\n",
    "            w_tot_3_a=[]\n",
    "            w_tot_1_b=[]\n",
    "            w_tot_2_b=[]\n",
    "            w_tot_3_b=[]\n",
    "            w_tot_1_c=[]\n",
    "            w_tot_2_c=[]\n",
    "            w_tot_3_c=[]            \n",
    "            for nn1 in df_all[(df_all['index']==i)]['neighbors']: #.drop_duplicates():\n",
    "                if (i,nn1) not in nn1_old and nn1!=i:\n",
    "                    nn1_old.append((i,nn1))\n",
    "                    if len(df_all[df_all['index']==nn1])==0:\n",
    "                        df_all, df_all_atom=get_atomic_env(nn1)\n",
    "                    area_tot_1=(df_all[df_all['index']==nn1]['face_areas_r']**1).sum()\n",
    "                    area_tot_1_a=(df_all[df_all['index']==nn1]['face_areas_r_a']**1).sum()\n",
    "                    area_tot_1_b=(df_all[df_all['index']==nn1]['face_areas_r_b']**1).sum()\n",
    "                    area_tot_1_c=(df_all[df_all['index']==nn1]['face_areas_r_c']**1).sum()\n",
    "                    for area_1, area_1_a, area_1_b, area_1_c, element_1, x, y, z in df_all[(df_all['index']==nn1)&(df_all['neighbors']==i)][['face_areas_r','face_areas_r_a','face_areas_r_b','face_areas_r_c','symbol','dist_x','dist_y','dist_z']].values:\n",
    "                        if element_1!=element_0:\n",
    "                            area_1=0\n",
    "                            area_1_a=0\n",
    "                            area_1_b=0\n",
    "                            area_1_c=0                            \n",
    "                        w_tot_1.append(area_1/area_tot_1)                            \n",
    "                        w_tot_1_a.append(area_1_a/area_tot_1_a)\n",
    "                        w_tot_1_b.append(area_1_b/area_tot_1_b)                        \n",
    "                        w_tot_1_c.append(area_1_c/area_tot_1_c)\n",
    "\n",
    "                        for nn2 in df_all[(df_all['index']==nn1)]['neighbors']: #.drop_duplicates():\n",
    "                            if (i,nn1,nn2) not in nn2_old and nn2!=i and nn2!=nn1 and nn1!=i:\n",
    "                                nn2_old.append((i,nn1,nn2))\n",
    "                                if len(df_all[df_all['index']==nn2])==0:\n",
    "                                    df_all, df_all_atom=get_atomic_env(nn2)\n",
    "                                area_tot_2=(df_all[df_all['index']==nn2 ]['face_areas_r']**1).sum()\n",
    "                                area_tot_2_a=(df_all[df_all['index']==nn2]['face_areas_r_a']**1).sum()\n",
    "                                area_tot_2_b=(df_all[df_all['index']==nn2]['face_areas_r_b']**1).sum()\n",
    "                                area_tot_2_c=(df_all[df_all['index']==nn2]['face_areas_r_c']**1).sum()                                \n",
    "                                for area_2, area_2_a, area_2_b, area_2_c, element_2, x, y, z in df_all[(df_all['index']==nn2)&(df_all['neighbors']==nn1)][['face_areas_r','face_areas_r_a','face_areas_r_b','face_areas_r_c','symbol','dist_x','dist_y','dist_z']].values:\n",
    "                                    if element_2!=element_1:\n",
    "                                        area_2=0\n",
    "                                        area_2_a=0\n",
    "                                        area_2_b=0\n",
    "                                        area_2_c=0                                        \n",
    "                                    w_tot_2.append(area_2/area_tot_2*area_1/(area_tot_1-area_2))                                        \n",
    "                                    w_tot_2_a.append(area_2_a/area_tot_2_a*area_1_a/(area_tot_1_a-area_2_a))\n",
    "                                    w_tot_2_b.append(area_2_b/area_tot_2_b*area_1_b/(area_tot_1_b-area_2_b))\n",
    "                                    w_tot_2_c.append(area_2_c/area_tot_2_c*area_1_c/(area_tot_1_c-area_2_c))\n",
    "                                    \n",
    "                                    for nn3 in df_all[(df_all['index']==nn2)]['neighbors']: #.drop_duplicates():\n",
    "                                        if (i,nn1,nn2,nn3) not in nn3_old and nn3!=i and nn3!=nn2 and nn3!=nn1 and nn1!=nn2 and nn2!=i and nn1!=i:\n",
    "                                            nn3_old.append((i,nn1,nn2,nn3))\n",
    "                                            if len(df_all[df_all['index']==nn3])==0:\n",
    "                                                df_all, df_all_atom=get_atomic_env(nn3)                                            \n",
    "                                            area_tot_3=(df_all[df_all['index']==nn3]['face_areas_r']**1).sum() \n",
    "                                            area_tot_3_a=(df_all[df_all['index']==nn3]['face_areas_r_a']**1).sum()\n",
    "                                            area_tot_3_b=(df_all[df_all['index']==nn3]['face_areas_r_b']**1).sum()\n",
    "                                            area_tot_3_c=(df_all[df_all['index']==nn3]['face_areas_r_c']**1).sum()                                                 \n",
    "                                            for area_3, area_3_a, area_3_b, area_3_c, element_3, x, y, z in df_all[(df_all['index']==nn3)&(df_all['neighbors']==nn2)][['face_areas_r','face_areas_r_a','face_areas_r_b','face_areas_r_c','symbol','dist_x','dist_y','dist_z']].values:\n",
    "                                                if element_3!=element_2:\n",
    "                                                    area_3=0\n",
    "                                                    area_3_a=0\n",
    "                                                    area_3_b=0\n",
    "                                                    area_3_c=0\n",
    "                                                w_tot_3.append(area_3/area_tot_3*area_2/(area_tot_2-area_3)*area_1/(area_tot_1-area_2))                                                    \n",
    "                                                w_tot_3_a.append(area_3_a/area_tot_3_a*area_2_a/(area_tot_2_a-area_3_a)*area_1_a/(area_tot_1_a-area_2_a))\n",
    "                                                w_tot_3_b.append(area_3_b/area_tot_3_b*area_2_b/(area_tot_2_b-area_3_b)*area_1_b/(area_tot_1_b-area_2_b))\n",
    "                                                w_tot_3_c.append(area_3_c/area_tot_3_c*area_2_c/(area_tot_2_c-area_3_c)*area_1_c/(area_tot_1_c-area_2_b))\n",
    "            list_of_weights=[w_tot_1,w_tot_2,w_tot_3,w_tot_1_a,w_tot_2_a,w_tot_3_a,w_tot_1_b,w_tot_2_b,w_tot_3_b,w_tot_1_c,w_tot_2_c,w_tot_3_c]                                   \n",
    "\n",
    "\n",
    "            for k in range(len(list_of_dict)):\n",
    "                list_of_dict[k][i].append(np.sum(list_of_weights[k]))\n",
    "                \n",
    "    df_all_atom.to_csv(configuration+'_atomic_features.csv',index=False)\n",
    "    return [tuple(k for k in [ind]+list_of_dict)]\n",
    "\n",
    "\n",
    "\n",
    "all_tuples=indices\n",
    "\n",
    "comps = tuple(enumerate(all_tuples))\n",
    "\n",
    "chunksize = int(math.ceil(len(comps)/N_processors))\n",
    "jobs = tuple(slice_iterable(comps, chunksize))\n",
    "\n",
    "pool = mp.Pool(processes=N_processors)\n",
    "work_res = pool.map_async(worker, jobs)\n",
    "\n",
    "list_of_weights = [[] for _ in range(12)]\n",
    "\n",
    "for i in indices:\n",
    "       \n",
    "    list_of_orders_tmp = [[] for _ in range(12)]\n",
    "\n",
    "    for result in list(map(itemgetter(1,2,3,4,5,6,7,8,9,10,11,12), sorted(itertools.chain(*work_res.get())))):\n",
    "    \n",
    "\n",
    "            \n",
    "            for k in range(12):\n",
    "                list_of_orders_tmp[k].append(result[k][i])\n",
    "\n",
    "    for k in range(12):\n",
    "        list_of_weights[k].append(sum(np.array(list_of_orders_tmp[k]).sum()))\n",
    "    \n",
    "\n",
    "\n",
    "features=['1_order','2_order','3_order','1_order_a','2_order_a','3_order_a','1_order_b','2_order_b','3_order_b','1_order_c','2_order_c','3_order_c']\n",
    "for k in range(len(features)):\n",
    "    df_all_atom[features[k]]=np.round(list_of_weights[k],n_decimals)\n",
    "df_all_atom['index']=indices\n",
    "\n",
    "df_all_atom_tmp=pd.read_csv(configuration+'_atomic_features.csv')\n",
    "\n",
    "df_combined=df_all_atom_tmp.merge(df_all_atom,on='index')\n",
    "\n",
    "list_species=sorted(structure.species)\n",
    "\n",
    "my_dict = {i:list_species.count(i) for i in list_species}\n",
    "\n",
    "np.array(list(my_dict.values()))/sum(np.array(list(my_dict.values())))\n",
    "\n",
    "list(my_dict.keys())\n",
    "\n",
    "df_combined=df_all_atom_tmp.merge(df_all_atom,on='index')\n",
    "\n",
    "for i in range(len(list(my_dict.keys()))):\n",
    "    df_combined[str(list(my_dict.keys())[i])+\"_conc\"]=[(np.array(list(my_dict.values()))/sum(np.array(list(my_dict.values()))))[i]]*len(df_combined)\n",
    "\n",
    "\n",
    "df_combined.drop_duplicates('z').sort_values(by='z')[['symbol','1_order_a','1_order_b', '1_order_c',  '2_order_a','2_order_b', '2_order_c','3_order_a',  '3_order_b','3_order_c']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the calculated parameters\n",
    "\n",
    "#List obtained features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'symbol', 'maximum_packing_efficiency', 'bond_length',\n",
       "       'bond_length_a', 'bond_length_b', 'bond_length_c', 'var_bond_length',\n",
       "       'var_bond_length_a', 'var_bond_length_b', 'var_bond_length_c',\n",
       "       'min_cell_volume', 'max_cell_volume', 'mean_cell_volume',\n",
       "       'var_cell_volume', 'tot_cell_volume', 'mean_face_area', 'max_face_area',\n",
       "       'min_face_area', 'var_face_area', 'tot_face_area', 'mean_face_area_a',\n",
       "       'max_face_area_a', 'min_face_area_a', 'var_face_area_a',\n",
       "       'tot_face_area_a', 'mean_face_area_b', 'max_face_area_b',\n",
       "       'min_face_area_b', 'var_face_area_b', 'tot_face_area_b',\n",
       "       'mean_face_area_c', 'max_face_area_c', 'min_face_area_c',\n",
       "       'var_face_area_c', 'tot_face_area_c', 'coordination', 'coordination_a',\n",
       "       'coordination_b', 'coordination_c', 'electronegativities',\n",
       "       'ionic_character', 'electronegativities_a', 'ionic_character_a',\n",
       "       'electronegativities_b', 'ionic_character_b', 'electronegativities_c',\n",
       "       'ionic_character_c', 'lat_a', 'lat_b', 'lat_c', 'x', 'y', 'z',\n",
       "       '1_order', '2_order', '3_order', '1_order_a', '2_order_a', '3_order_a',\n",
       "       '1_order_b', '2_order_b', '3_order_b', '1_order_c', '2_order_c',\n",
       "       '3_order_c', 'Si_conc', 'Ge_conc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.to_csv(configuration+'_combined_features.csv',index=False)\n",
    "\n",
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
